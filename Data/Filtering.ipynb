{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/zer0deck/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/zer0deck/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/zer0deck/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Data.csv', sep= ';', index_col=0)\n",
    "df = df.dropna()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Class</th>\n",
       "      <th>True class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>This is what it’s all about. The cut and thrus...</td>\n",
       "      <td>Sport</td>\n",
       "      <td>Sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>WHO WILL WIN? ITALY - 1.66 SWITZERLAND-6.0DRAW...</td>\n",
       "      <td>Sport</td>\n",
       "      <td>Sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>Laporta becomes a member of the RFEF Council.</td>\n",
       "      <td>Sport</td>\n",
       "      <td>Sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>HE'S DONE IT!! Eliud Kipchoge achieves 'the im...</td>\n",
       "      <td>Sport</td>\n",
       "      <td>Sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>I know this is not the first time I've said th...</td>\n",
       "      <td>Sport</td>\n",
       "      <td>Sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>Finish pencil work of Anthony Oluwafemi Olasen...</td>\n",
       "      <td>Sport</td>\n",
       "      <td>Sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>Greetings from the Sport Industry Awards!</td>\n",
       "      <td>Sport</td>\n",
       "      <td>Sport</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  Class True class\n",
       "Index                                                                     \n",
       "1.0    This is what it’s all about. The cut and thrus...  Sport      Sport\n",
       "2.0    WHO WILL WIN? ITALY - 1.66 SWITZERLAND-6.0DRAW...  Sport      Sport\n",
       "3.0        Laporta becomes a member of the RFEF Council.  Sport      Sport\n",
       "4.0    HE'S DONE IT!! Eliud Kipchoge achieves 'the im...  Sport      Sport\n",
       "5.0    I know this is not the first time I've said th...  Sport      Sport\n",
       "6.0    Finish pencil work of Anthony Oluwafemi Olasen...  Sport      Sport\n",
       "7.0            Greetings from the Sport Industry Awards!  Sport      Sport"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates(subset={'Text'}, inplace=True)\n",
    "df.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = df['True class'].unique().tolist()\n",
    "for i in range (0, len(j)):\n",
    "    df.loc[df['True class'] == j[i], 'True class'] = i\n",
    "    df.loc[df['Class'] == j[i], 'Class'] = i\n",
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of contractions from https://en.wikipedia.org/wiki/Wikipedia%3aList_of_English_contractions\n",
    "contractions = { \n",
    "\"ain't\": \"am not\",\n",
    "\"aren't\": \"are not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he will\",\n",
    "\"he's\": \"he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how is\",\n",
    "\"i'd\": \"i would\",\n",
    "\"i'll\": \"i will\",\n",
    "\"i'm\": \"i am\",\n",
    "\"i've\": \"i have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it would\",\n",
    "\"it'll\": \"it will\",\n",
    "\"it's\": \"it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"needn't\": \"need not\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"she'd\": \"she would\",\n",
    "\"she'll\": \"she will\",\n",
    "\"she's\": \"she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"that'd\": \"that would\",\n",
    "\"that's\": \"that is\",\n",
    "\"there'd\": \"there had\",\n",
    "\"there's\": \"there is\",\n",
    "\"they'd\": \"they would\",\n",
    "\"they'll\": \"they will\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we would\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what will\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where is\",\n",
    "\"who'll\": \"who will\",\n",
    "\"who's\": \"who is\",\n",
    "\"won't\": \"will not\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"you'd\": \"you would\",\n",
    "\"you'll\": \"you will\",\n",
    "\"you're\": \"you are\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_filter(text, remove_stopwords = True):\n",
    "    '''Remove unwanted characters, stopwords, and format the text to create fewer nulls word embeddings'''\n",
    "    \n",
    "    # Convert words to lower case\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Replace contractions with their longer forms \n",
    "    if True:\n",
    "        text = text.split()\n",
    "        new_text = []\n",
    "        for word in text:\n",
    "            if word in contractions:\n",
    "                new_text.append(contractions[word])\n",
    "            else:\n",
    "                new_text.append(word)\n",
    "        text = \" \".join(new_text)\n",
    "    \n",
    "    # Format words and remove unwanted characters\n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\<a href', ' ', text)\n",
    "    text = re.sub(r'&amp;', '', text) \n",
    "    text = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', text)\n",
    "    text = re.sub(r'<br />', ' ', text)\n",
    "    text = re.sub(r'\\'', ' ', text)\n",
    "    \n",
    "    # remove stop words\n",
    "    if remove_stopwords:\n",
    "        text = text.split()\n",
    "        stops = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "        text = [w for w in text if not w in stops]\n",
    "        text = \" \".join(text)\n",
    "\n",
    "    # Tokenize each word\n",
    "    text =  nltk.WordPunctTokenizer().tokenize(text)\n",
    "        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Tokenized Text'] = list(map(text_filter, df['Text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Class</th>\n",
       "      <th>True class</th>\n",
       "      <th>Tokenized Text</th>\n",
       "      <th>lemmatized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dolores O'Riordan (born 1971 - died 2018) was ...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[dolores, riordan, born, 1971, died, 2018, one...</td>\n",
       "      <td>[dolores, riordan, born, 1971, died, 2018, one...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>As they say “Genius leaves Clues” and Ronaldo ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[say, “, genius, leaves, clues, ”, ronaldo, ce...</td>\n",
       "      <td>[say, “, genius, leaf, clue, ”, ronaldo, certa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What's your favorite accessory??</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[favorite, accessory]</td>\n",
       "      <td>[favorite, accessory]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What have we just witnessed?!!!!!!Congrats ben...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[witnessed, congrats, benstokes38, congrats, e...</td>\n",
       "      <td>[witnessed, congrats, benstokes38, congrats, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kalpop is the joy, the passion, the mood and t...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[kalpop, joy, passion, mood, whole, vibe, around]</td>\n",
       "      <td>[kalpop, joy, passion, mood, whole, vibe, around]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I've seen this video over and over again.</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[seen, video]</td>\n",
       "      <td>[seen, video]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Jan. 7, 1995 Green Day were #1 on the Billboar...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[jan, 7, 1995, green, day, 1, billboard, moder...</td>\n",
       "      <td>[jan, 7, 1995, green, day, 1, billboard, moder...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text Class True class  \\\n",
       "0  Dolores O'Riordan (born 1971 - died 2018) was ...     4          4   \n",
       "1  As they say “Genius leaves Clues” and Ronaldo ...     0          0   \n",
       "2                   What's your favorite accessory??     4          4   \n",
       "3  What have we just witnessed?!!!!!!Congrats ben...     0          0   \n",
       "4  Kalpop is the joy, the passion, the mood and t...     4          4   \n",
       "5          I've seen this video over and over again.     4          4   \n",
       "6  Jan. 7, 1995 Green Day were #1 on the Billboar...     4          4   \n",
       "\n",
       "                                      Tokenized Text  \\\n",
       "0  [dolores, riordan, born, 1971, died, 2018, one...   \n",
       "1  [say, “, genius, leaves, clues, ”, ronaldo, ce...   \n",
       "2                              [favorite, accessory]   \n",
       "3  [witnessed, congrats, benstokes38, congrats, e...   \n",
       "4  [kalpop, joy, passion, mood, whole, vibe, around]   \n",
       "5                                      [seen, video]   \n",
       "6  [jan, 7, 1995, green, day, 1, billboard, moder...   \n",
       "\n",
       "                                     lemmatized_text  \n",
       "0  [dolores, riordan, born, 1971, died, 2018, one...  \n",
       "1  [say, “, genius, leaf, clue, ”, ronaldo, certa...  \n",
       "2                              [favorite, accessory]  \n",
       "3  [witnessed, congrats, benstokes38, congrats, e...  \n",
       "4  [kalpop, joy, passion, mood, whole, vibe, around]  \n",
       "5                                      [seen, video]  \n",
       "6  [jan, 7, 1995, green, day, 1, billboard, moder...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lemmatized_words(text):\n",
    "    lemm = nltk.stem.WordNetLemmatizer()\n",
    "    df['lemmatized_text'] = list(map(lambda word:\n",
    "                                     list(map(lemm.lemmatize, word)),\n",
    "                                     df['Tokenized Text']))\n",
    "    \n",
    "\n",
    "lemmatized_words(df['Tokenized Text'])\n",
    "df.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Class</th>\n",
       "      <th>True class</th>\n",
       "      <th>Tokenized Text</th>\n",
       "      <th>lemmatized_text</th>\n",
       "      <th>Label</th>\n",
       "      <th>True Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dolores O'Riordan (born 1971 - died 2018) was ...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[dolores, riordan, born, 1971, died, 2018, one...</td>\n",
       "      <td>[dolores, riordan, born, 1971, died, 2018, one...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>As they say “Genius leaves Clues” and Ronaldo ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[say, “, genius, leaves, clues, ”, ronaldo, ce...</td>\n",
       "      <td>[say, “, genius, leaf, clue, ”, ronaldo, certa...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What's your favorite accessory??</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[favorite, accessory]</td>\n",
       "      <td>[favorite, accessory]</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What have we just witnessed?!!!!!!Congrats ben...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[witnessed, congrats, benstokes38, congrats, e...</td>\n",
       "      <td>[witnessed, congrats, benstokes38, congrats, e...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kalpop is the joy, the passion, the mood and t...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[kalpop, joy, passion, mood, whole, vibe, around]</td>\n",
       "      <td>[kalpop, joy, passion, mood, whole, vibe, around]</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I've seen this video over and over again.</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[seen, video]</td>\n",
       "      <td>[seen, video]</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Jan. 7, 1995 Green Day were #1 on the Billboar...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[jan, 7, 1995, green, day, 1, billboard, moder...</td>\n",
       "      <td>[jan, 7, 1995, green, day, 1, billboard, moder...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text Class True class  \\\n",
       "0  Dolores O'Riordan (born 1971 - died 2018) was ...     4          4   \n",
       "1  As they say “Genius leaves Clues” and Ronaldo ...     0          0   \n",
       "2                   What's your favorite accessory??     4          4   \n",
       "3  What have we just witnessed?!!!!!!Congrats ben...     0          0   \n",
       "4  Kalpop is the joy, the passion, the mood and t...     4          4   \n",
       "5          I've seen this video over and over again.     4          4   \n",
       "6  Jan. 7, 1995 Green Day were #1 on the Billboar...     4          4   \n",
       "\n",
       "                                      Tokenized Text  \\\n",
       "0  [dolores, riordan, born, 1971, died, 2018, one...   \n",
       "1  [say, “, genius, leaves, clues, ”, ronaldo, ce...   \n",
       "2                              [favorite, accessory]   \n",
       "3  [witnessed, congrats, benstokes38, congrats, e...   \n",
       "4  [kalpop, joy, passion, mood, whole, vibe, around]   \n",
       "5                                      [seen, video]   \n",
       "6  [jan, 7, 1995, green, day, 1, billboard, moder...   \n",
       "\n",
       "                                     lemmatized_text  Label  True Label  \n",
       "0  [dolores, riordan, born, 1971, died, 2018, one...      0         NaN  \n",
       "1  [say, “, genius, leaf, clue, ”, ronaldo, certa...      1         1.0  \n",
       "2                              [favorite, accessory]      0         NaN  \n",
       "3  [witnessed, congrats, benstokes38, congrats, e...      1         1.0  \n",
       "4  [kalpop, joy, passion, mood, whole, vibe, around]      0         NaN  \n",
       "5                                      [seen, video]      0         NaN  \n",
       "6  [jan, 7, 1995, green, day, 1, billboard, moder...      0         NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Label'] = 0\n",
    "df.loc[df['True class'] == 0, ['True Label']] = 1\n",
    "df.loc[df['Class'] == 0, ['Label']] = 1\n",
    "df.head(7)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
