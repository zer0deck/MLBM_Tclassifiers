{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/zer0deck/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/zer0deck/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/zer0deck/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Libs initialization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "import statistics\n",
    "import math\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "import re\n",
    "\n",
    "# import scipy\n",
    "# from scipy.signal import fftconvolve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data file preparation\n",
    "</br> Retrieving Data from a dataset collected using the Twitter API, renaming classes and randomizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Class</th>\n",
       "      <th>True class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is what it’s all about. The cut and thrus...</td>\n",
       "      <td>Sport</td>\n",
       "      <td>Sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WHO WILL WIN? ITALY - 1.66 SWITZERLAND-6.0DRAW...</td>\n",
       "      <td>Sport</td>\n",
       "      <td>Sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Laporta becomes a member of the RFEF Council.</td>\n",
       "      <td>Sport</td>\n",
       "      <td>Sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HE'S DONE IT!! Eliud Kipchoge achieves 'the im...</td>\n",
       "      <td>Sport</td>\n",
       "      <td>Sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I know this is not the first time I've said th...</td>\n",
       "      <td>Sport</td>\n",
       "      <td>Sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Finish pencil work of Anthony Oluwafemi Olasen...</td>\n",
       "      <td>Sport</td>\n",
       "      <td>Sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Greetings from the Sport Industry Awards!</td>\n",
       "      <td>Sport</td>\n",
       "      <td>Sport</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  Class True class\n",
       "Index                                                                     \n",
       "1      This is what it’s all about. The cut and thrus...  Sport      Sport\n",
       "2      WHO WILL WIN? ITALY - 1.66 SWITZERLAND-6.0DRAW...  Sport      Sport\n",
       "3          Laporta becomes a member of the RFEF Council.  Sport      Sport\n",
       "4      HE'S DONE IT!! Eliud Kipchoge achieves 'the im...  Sport      Sport\n",
       "5      I know this is not the first time I've said th...  Sport      Sport\n",
       "6      Finish pencil work of Anthony Oluwafemi Olasen...  Sport      Sport\n",
       "7              Greetings from the Sport Industry Awards!  Sport      Sport"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Data.csv', sep= ';', index_col=0)\n",
    "df = df.dropna()\n",
    "df.shape\n",
    "df.drop_duplicates(subset={'Text'}, inplace=True)\n",
    "df.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Class names to codes/numbers\n",
    "j = df['True class'].unique().tolist()\n",
    "z = df['True class'].unique().tolist()\n",
    "for i in range (0, len(j)):\n",
    "    df.loc[df['True class'] == j[i], 'True class'] = i\n",
    "    df.loc[df['Class'] == j[i], 'Class'] = i\n",
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A List of English contractions from https://en.wikipedia.org/wiki/Wikipedia%3aList_of_English_contractions\n",
    "c_dict = { \n",
    "\"ain't\": \"am not\",\n",
    "\"aren't\": \"are not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he will\",\n",
    "\"he's\": \"he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how is\",\n",
    "\"i'd\": \"i would\",\n",
    "\"i'll\": \"i will\",\n",
    "\"i'm\": \"i am\",\n",
    "\"i've\": \"i have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it would\",\n",
    "\"it'll\": \"it will\",\n",
    "\"it's\": \"it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"needn't\": \"need not\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"she'd\": \"she would\",\n",
    "\"she'll\": \"she will\",\n",
    "\"she's\": \"she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"that'd\": \"that would\",\n",
    "\"that's\": \"that is\",\n",
    "\"there'd\": \"there had\",\n",
    "\"there's\": \"there is\",\n",
    "\"they'd\": \"they would\",\n",
    "\"they'll\": \"they will\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we would\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what will\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where is\",\n",
    "\"who'll\": \"who will\",\n",
    "\"who's\": \"who is\",\n",
    "\"won't\": \"will not\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"you'd\": \"you would\",\n",
    "\"you'll\": \"you will\",\n",
    "\"you're\": \"you are\",\n",
    "\"1st\": \"first\",\n",
    "\"2nd\": \"second\",\n",
    "\"3rd\": \"third\",\n",
    "\"4th\": \"forth\",\n",
    "\"5th\": \"fifth\",\n",
    "\"6th\": \"sixth\",\n",
    "\"7th\": \"seventh\",\n",
    "\"8th\": \"eighth\",\n",
    "\"9th\": \"ninth\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Text Filtering\n",
    "</br> Four-step raw tex filter, using [nltk](https://www.nltk.org) libraries. Filter includes:\n",
    "* Constructions filter (special thanks for [arturomp](https://stackoverflow.com/users/583834/arturomp) for [converting](https://stackoverflow.com/posts/19794953/revisions) wikipedia contraction-to-expansion page into a python dictionary)\n",
    "* Stopwords filter\n",
    "* Unwanted characters filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_filter(text):\n",
    "    \n",
    "    # Convert words to lower case\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove constructions\n",
    "    text = text.split()\n",
    "    new_text = []\n",
    "    for word in text:\n",
    "        if word in c_dict:\n",
    "            new_text.append(c_dict[word])\n",
    "        else:\n",
    "            new_text.append(word)\n",
    "    text = \" \".join(new_text)\n",
    "\n",
    "    # Remove unwanted characters\n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', text)\n",
    "    text = re.sub(r'\\<a href', ' ', text)\n",
    "    text = re.sub(r'&amp;', '', text) \n",
    "    text = re.sub(r'<br />', ' ', text)\n",
    "    text = re.sub(r'\\'', ' ', text)\n",
    "\n",
    "    # Remove SW\n",
    "    text = text.split()\n",
    "    sw = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "    text = [w for w in text if not w in sw]\n",
    "    text = \" \".join(text)\n",
    "\n",
    "    # Split numbers and words\n",
    "    text = text.split()\n",
    "    new_text2 = []\n",
    "    for word in text:\n",
    "        if (word.isalpha() or word.isdigit()):\n",
    "            new_text2.append(word)\n",
    "        else:\n",
    "            for i in range(0,len(word)-1):\n",
    "                if ((word[i].isdigit() and word[i+1].isalpha()) or (word[i+1].isdigit() and word[i].isalpha())):\n",
    "                    word1 = word[0:(i+1)]\n",
    "                    word2 = word[(i+1):len(word)]\n",
    "                    new_text2.append(word1)\n",
    "                    new_text2.append(word2)\n",
    "    text = \" \".join(new_text2)\n",
    "        \n",
    "    return text\n",
    "\n",
    "def text_tokenizer(text):\n",
    "    text =  nltk.WordPunctTokenizer().tokenize(text)\n",
    "    return text\n",
    "\n",
    "def joinclean(text):\n",
    "    text = str(' '.join(text))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Class</th>\n",
       "      <th>True class</th>\n",
       "      <th>CleanedText</th>\n",
       "      <th>TokenizedText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RUNNERS ALL AROUND THE WORLD Post photos weari...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>runner around world post photo wearing space r...</td>\n",
       "      <td>[runner, around, world, post, photo, wearing, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>After WFH now it's time for PFH? (Read: Pracha...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>wfh time pfh read prachar politics home politi...</td>\n",
       "      <td>[wfh, time, pfh, read, prachar, politics, home...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BTS ｜ SYSTEM last collection, accessory produc...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>bts system last collection accessory product t...</td>\n",
       "      <td>[bts, system, last, collection, accessory, pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>“Late Manohar Parrikar will always be by idol,...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>manohar parrikar always idol resigning party t...</td>\n",
       "      <td>[manohar, parrikar, always, idol, resigning, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Day#1394 of running min 10 km/day Total-16448 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>day 1394 running min 10 km day total 16448 km ...</td>\n",
       "      <td>[day, 1394, running, min, 10, km, day, total, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WHO WILL WIN? ITALY - 1.66 SWITZERLAND-6.0DRAW...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>win italy 1 66 switzerland 6 0 draw 3 85</td>\n",
       "      <td>[win, italy, 1, 66, switzerland, 6, 0, draw, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>This can't reproduced easily or economically. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>cannot reproduced easily economically able bri...</td>\n",
       "      <td>[cannot, reproduced, easily, economically, abl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text Class True class  \\\n",
       "0  RUNNERS ALL AROUND THE WORLD Post photos weari...     2          2   \n",
       "1  After WFH now it's time for PFH? (Read: Pracha...     1          1   \n",
       "2  BTS ｜ SYSTEM last collection, accessory produc...     2          2   \n",
       "3  “Late Manohar Parrikar will always be by idol,...     1          1   \n",
       "4  Day#1394 of running min 10 km/day Total-16448 ...     0          0   \n",
       "5  WHO WILL WIN? ITALY - 1.66 SWITZERLAND-6.0DRAW...     0          0   \n",
       "6  This can't reproduced easily or economically. ...     2          2   \n",
       "\n",
       "                                         CleanedText  \\\n",
       "0  runner around world post photo wearing space r...   \n",
       "1  wfh time pfh read prachar politics home politi...   \n",
       "2  bts system last collection accessory product t...   \n",
       "3  manohar parrikar always idol resigning party t...   \n",
       "4  day 1394 running min 10 km day total 16448 km ...   \n",
       "5           win italy 1 66 switzerland 6 0 draw 3 85   \n",
       "6  cannot reproduced easily economically able bri...   \n",
       "\n",
       "                                       TokenizedText  \n",
       "0  [runner, around, world, post, photo, wearing, ...  \n",
       "1  [wfh, time, pfh, read, prachar, politics, home...  \n",
       "2  [bts, system, last, collection, accessory, pro...  \n",
       "3  [manohar, parrikar, always, idol, resigning, p...  \n",
       "4  [day, 1394, running, min, 10, km, day, total, ...  \n",
       "5  [win, italy, 1, 66, switzerland, 6, 0, draw, 3...  \n",
       "6  [cannot, reproduced, easily, economically, abl...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['CleanedText'] = list(map(text_filter, df['Text']))\n",
    "df['TokenizedText'] = list(map(text_tokenizer, df['CleanedText']))\n",
    "lemm = nltk.stem.WordNetLemmatizer()\n",
    "df['TokenizedText'] = list(map(lambda word:\n",
    "                                     list(map(lemm.lemmatize, word)),\n",
    "                                     df['TokenizedText']))\n",
    "df['CleanedText'] = list(map(joinclean, df['TokenizedText']))\n",
    "df.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating full corpus of words\n",
    "corpus = []\n",
    "for i in range(0, len(df)):\n",
    "    corpus.append(df.loc[i, 'TokenizedText'])\n",
    "    # w_list = df.loc[i, 'Tokenized Text']\n",
    "    # for j in range (0, len(w_list)):\n",
    "    #     corpus.append(w_list[j])\n",
    "# corpus = set(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. TF-IDF\n",
    "</br> This part count TF-IDF vectors for dataset based on the tokenized words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf(text):\n",
    "    d = {}\n",
    "    tf_text = collections.Counter(text)\n",
    "    for i in tf_text:\n",
    "        d[i] = tf_text[i]/float(len(text))\n",
    "    return d\n",
    "def idf(word, corpus):\n",
    "        return math.log10(len(corpus)/sum([1.0 for i in corpus if word in i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7f/v45zg7ms5gzd2qjc6tqr5nwh0000gn/T/ipykernel_43576/2859320738.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.TokenizedText[i] = word_list\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Class</th>\n",
       "      <th>True class</th>\n",
       "      <th>CleanedText</th>\n",
       "      <th>TokenizedText</th>\n",
       "      <th>Words quantity</th>\n",
       "      <th>TF-IDF mean</th>\n",
       "      <th>TF-IDF sum</th>\n",
       "      <th>TF-IDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RUNNERS ALL AROUND THE WORLD Post photos weari...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>runner around world post photo wearing space r...</td>\n",
       "      <td>[runner, runner, explorer, runner, seafoamserp...</td>\n",
       "      <td>25</td>\n",
       "      <td>2.830910</td>\n",
       "      <td>3.446952</td>\n",
       "      <td>[1.4350901541679493, 3.4324729176496476, 0.538...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>After WFH now it's time for PFH? (Read: Pracha...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>wfh time pfh read prachar politics home politi...</td>\n",
       "      <td>[time, high, time, contestant, creative]</td>\n",
       "      <td>20</td>\n",
       "      <td>0.589459</td>\n",
       "      <td>2.285503</td>\n",
       "      <td>[0.5567267694452995, 0.5385693838554461, 0.774...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BTS ｜ SYSTEM last collection, accessory produc...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>bts system last collection accessory product t...</td>\n",
       "      <td>[product, two, hat, two, hat]</td>\n",
       "      <td>14</td>\n",
       "      <td>1.326736</td>\n",
       "      <td>3.107692</td>\n",
       "      <td>[0.5385693838554461, 0.8862902658230271, 0.956...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>“Late Manohar Parrikar will always be by idol,...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>manohar parrikar always idol resigning party t...</td>\n",
       "      <td>[parrikar, party, party, parrikar, rafael]</td>\n",
       "      <td>12</td>\n",
       "      <td>1.267942</td>\n",
       "      <td>3.272661</td>\n",
       "      <td>[1.0771387677108921, 0.677138767710892, 1.1462...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Day#1394 of running min 10 km/day Total-16448 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>day 1394 running min 10 km day total 16448 km ...</td>\n",
       "      <td>[km, day, 16448, km, 03]</td>\n",
       "      <td>13</td>\n",
       "      <td>1.064214</td>\n",
       "      <td>3.049750</td>\n",
       "      <td>[1.0771387677108921, 0.26622381665192746, 0.53...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WHO WILL WIN? ITALY - 1.66 SWITZERLAND-6.0DRAW...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>win italy 1 66 switzerland 6 0 draw 3 85</td>\n",
       "      <td>[italy, 66, switzerland, draw, 85]</td>\n",
       "      <td>10</td>\n",
       "      <td>0.538569</td>\n",
       "      <td>2.315468</td>\n",
       "      <td>[0.5385693838554461, 0.5385693838554461, 0.538...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>This can't reproduced easily or economically. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>cannot reproduced easily economically able bri...</td>\n",
       "      <td>[easily, bring, highest, shortest, possible]</td>\n",
       "      <td>11</td>\n",
       "      <td>0.538569</td>\n",
       "      <td>2.374296</td>\n",
       "      <td>[0.5385693838554461, 0.5385693838554461, 0.538...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text Class True class  \\\n",
       "0  RUNNERS ALL AROUND THE WORLD Post photos weari...     2          2   \n",
       "1  After WFH now it's time for PFH? (Read: Pracha...     1          1   \n",
       "2  BTS ｜ SYSTEM last collection, accessory produc...     2          2   \n",
       "3  “Late Manohar Parrikar will always be by idol,...     1          1   \n",
       "4  Day#1394 of running min 10 km/day Total-16448 ...     0          0   \n",
       "5  WHO WILL WIN? ITALY - 1.66 SWITZERLAND-6.0DRAW...     0          0   \n",
       "6  This can't reproduced easily or economically. ...     2          2   \n",
       "\n",
       "                                         CleanedText  \\\n",
       "0  runner around world post photo wearing space r...   \n",
       "1  wfh time pfh read prachar politics home politi...   \n",
       "2  bts system last collection accessory product t...   \n",
       "3  manohar parrikar always idol resigning party t...   \n",
       "4  day 1394 running min 10 km day total 16448 km ...   \n",
       "5           win italy 1 66 switzerland 6 0 draw 3 85   \n",
       "6  cannot reproduced easily economically able bri...   \n",
       "\n",
       "                                       TokenizedText  Words quantity  \\\n",
       "0  [runner, runner, explorer, runner, seafoamserp...              25   \n",
       "1           [time, high, time, contestant, creative]              20   \n",
       "2                      [product, two, hat, two, hat]              14   \n",
       "3         [parrikar, party, party, parrikar, rafael]              12   \n",
       "4                           [km, day, 16448, km, 03]              13   \n",
       "5                 [italy, 66, switzerland, draw, 85]              10   \n",
       "6       [easily, bring, highest, shortest, possible]              11   \n",
       "\n",
       "   TF-IDF mean  TF-IDF sum                                             TF-IDF  \n",
       "0     2.830910    3.446952  [1.4350901541679493, 3.4324729176496476, 0.538...  \n",
       "1     0.589459    2.285503  [0.5567267694452995, 0.5385693838554461, 0.774...  \n",
       "2     1.326736    3.107692  [0.5385693838554461, 0.8862902658230271, 0.956...  \n",
       "3     1.267942    3.272661  [1.0771387677108921, 0.677138767710892, 1.1462...  \n",
       "4     1.064214    3.049750  [1.0771387677108921, 0.26622381665192746, 0.53...  \n",
       "5     0.538569    2.315468  [0.5385693838554461, 0.5385693838554461, 0.538...  \n",
       "6     0.538569    2.374296  [0.5385693838554461, 0.5385693838554461, 0.538...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Words quantity'] = 0\n",
    "df['TF-IDF mean'] = 0\n",
    "df['TF-IDF sum'] = 0\n",
    "df['TF-IDF'] = 0\n",
    "list =[]\n",
    "\n",
    "for i in range(0, len(df)):\n",
    "\n",
    "    word_list = df.TokenizedText[i]\n",
    "\n",
    "    wv = []\n",
    "    t_f = tf(word_list)\n",
    "    for j in range(0, len(word_list)):\n",
    "        id_f = idf(word_list[j], corpus)\n",
    "        t_f[word_list[j]] = t_f[word_list[j]] * id_f \n",
    "        wv.append(t_f[word_list[j]])\n",
    "\n",
    "    # Addind the words quantity and the TF-IDF sum in the columns\n",
    "    df.loc[i, ['Words quantity']] = len(word_list)\n",
    "    df.loc[i, ['TF-IDF sum']] = sum(t_f.values())\n",
    "\n",
    "    t_f.clear()\n",
    "    # Deleting less importaint words if there are more than 5\n",
    "    if len(word_list)>5:\n",
    "        while len(wv)>5:\n",
    "            word_list.pop(wv.index(min(wv)))\n",
    "            wv.remove(min(wv))\n",
    "        wv = []\n",
    "        t_f = tf(word_list)\n",
    "        for j in range(0, len(word_list)):\n",
    "            id_f = idf(word_list[j], corpus)\n",
    "            t_f[word_list[j]] = t_f[word_list[j]] * id_f \n",
    "            wv.append(t_f[word_list[j]])\n",
    "        df.TokenizedText[i] = word_list\n",
    "    \n",
    "    # Addind the TF-IDF average in the columns\n",
    "    df.loc[i, ['TF-IDF mean']] = statistics.mean(wv)\n",
    "\n",
    "    # We create linear convolution of our TF-IDF parameter to fit it into list of 5 objects\n",
    "    # That solves problems of many-variable TF-IDF vectors\n",
    "    # y = np.array ([1, 1, 1, 1, 1])\n",
    "    # npwv = fftconvolve(y, wv, mode='same', axes=None)\n",
    "    # list.append(npwv)\n",
    "\n",
    "    wvnp = np.zeros(5)\n",
    "    for i in range(0, len(wv)):\n",
    "        wvnp[i]=wv[i]\n",
    "    list.append(wvnp)\n",
    "df['TF-IDF'] = list\n",
    "df.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Filtered Data output\n",
    "</br> Data is output to files by categories for Logistic Regression and to one file for other types of algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CleanedText</th>\n",
       "      <th>TokenizedText</th>\n",
       "      <th>TF-IDF</th>\n",
       "      <th>TF-IDF sum</th>\n",
       "      <th>Words quantity</th>\n",
       "      <th>TF-IDF mean</th>\n",
       "      <th>Class</th>\n",
       "      <th>True class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>runner around world post photo wearing space r...</td>\n",
       "      <td>[runner, runner, explorer, runner, seafoamserp...</td>\n",
       "      <td>[1.4350901541679493, 3.4324729176496476, 0.538...</td>\n",
       "      <td>3.446952</td>\n",
       "      <td>25</td>\n",
       "      <td>2.830910</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wfh time pfh read prachar politics home politi...</td>\n",
       "      <td>[time, high, time, contestant, creative]</td>\n",
       "      <td>[0.5567267694452995, 0.5385693838554461, 0.774...</td>\n",
       "      <td>2.285503</td>\n",
       "      <td>20</td>\n",
       "      <td>0.589459</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bts system last collection accessory product t...</td>\n",
       "      <td>[product, two, hat, two, hat]</td>\n",
       "      <td>[0.5385693838554461, 0.8862902658230271, 0.956...</td>\n",
       "      <td>3.107692</td>\n",
       "      <td>14</td>\n",
       "      <td>1.326736</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>manohar parrikar always idol resigning party t...</td>\n",
       "      <td>[parrikar, party, party, parrikar, rafael]</td>\n",
       "      <td>[1.0771387677108921, 0.677138767710892, 1.1462...</td>\n",
       "      <td>3.272661</td>\n",
       "      <td>12</td>\n",
       "      <td>1.267942</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>day 1394 running min 10 km day total 16448 km ...</td>\n",
       "      <td>[km, day, 16448, km, 03]</td>\n",
       "      <td>[1.0771387677108921, 0.26622381665192746, 0.53...</td>\n",
       "      <td>3.049750</td>\n",
       "      <td>13</td>\n",
       "      <td>1.064214</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>win italy 1 66 switzerland 6 0 draw 3 85</td>\n",
       "      <td>[italy, 66, switzerland, draw, 85]</td>\n",
       "      <td>[0.5385693838554461, 0.5385693838554461, 0.538...</td>\n",
       "      <td>2.315468</td>\n",
       "      <td>10</td>\n",
       "      <td>0.538569</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cannot reproduced easily economically able bri...</td>\n",
       "      <td>[easily, bring, highest, shortest, possible]</td>\n",
       "      <td>[0.5385693838554461, 0.5385693838554461, 0.538...</td>\n",
       "      <td>2.374296</td>\n",
       "      <td>11</td>\n",
       "      <td>0.538569</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         CleanedText  \\\n",
       "0  runner around world post photo wearing space r...   \n",
       "1  wfh time pfh read prachar politics home politi...   \n",
       "2  bts system last collection accessory product t...   \n",
       "3  manohar parrikar always idol resigning party t...   \n",
       "4  day 1394 running min 10 km day total 16448 km ...   \n",
       "5           win italy 1 66 switzerland 6 0 draw 3 85   \n",
       "6  cannot reproduced easily economically able bri...   \n",
       "\n",
       "                                       TokenizedText  \\\n",
       "0  [runner, runner, explorer, runner, seafoamserp...   \n",
       "1           [time, high, time, contestant, creative]   \n",
       "2                      [product, two, hat, two, hat]   \n",
       "3         [parrikar, party, party, parrikar, rafael]   \n",
       "4                           [km, day, 16448, km, 03]   \n",
       "5                 [italy, 66, switzerland, draw, 85]   \n",
       "6       [easily, bring, highest, shortest, possible]   \n",
       "\n",
       "                                              TF-IDF  TF-IDF sum  \\\n",
       "0  [1.4350901541679493, 3.4324729176496476, 0.538...    3.446952   \n",
       "1  [0.5567267694452995, 0.5385693838554461, 0.774...    2.285503   \n",
       "2  [0.5385693838554461, 0.8862902658230271, 0.956...    3.107692   \n",
       "3  [1.0771387677108921, 0.677138767710892, 1.1462...    3.272661   \n",
       "4  [1.0771387677108921, 0.26622381665192746, 0.53...    3.049750   \n",
       "5  [0.5385693838554461, 0.5385693838554461, 0.538...    2.315468   \n",
       "6  [0.5385693838554461, 0.5385693838554461, 0.538...    2.374296   \n",
       "\n",
       "   Words quantity  TF-IDF mean Class True class  \n",
       "0              25     2.830910     2          2  \n",
       "1              20     0.589459     1          1  \n",
       "2              14     1.326736     2          2  \n",
       "3              12     1.267942     1          1  \n",
       "4              13     1.064214     0          0  \n",
       "5              10     0.538569     0          0  \n",
       "6              11     0.538569     2          2  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the final dataset\n",
    "df = df[['CleanedText', 'TokenizedText', 'TF-IDF', 'TF-IDF sum', 'Words quantity', 'TF-IDF mean', 'Class', 'True class']]\n",
    "df.to_csv('FilteredData.csv', sep=';', encoding='utf-8', index=False)\n",
    "df.head(7)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
