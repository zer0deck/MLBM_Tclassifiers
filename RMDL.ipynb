{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.version_info(major=3, minor=9, micro=7, releaselevel='final', serial=0)\n",
      "sys.version_info(major=3, minor=9, micro=7, releaselevel='final', serial=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/zer0deck/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from RMDL import RMDL_Text as RMDL\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import reuters\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CleanedText</th>\n",
       "      <th>TokenizedText</th>\n",
       "      <th>TF-IDF</th>\n",
       "      <th>TF-IDF sum</th>\n",
       "      <th>Words quantity</th>\n",
       "      <th>TF-IDF mean</th>\n",
       "      <th>Class</th>\n",
       "      <th>True class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>runner around world post photo wearing space r...</td>\n",
       "      <td>['runner', 'runner', 'explorer', 'runner', 'se...</td>\n",
       "      <td>[1.43509015 3.43247292 0.53856938 8.20984681 0...</td>\n",
       "      <td>3.446952</td>\n",
       "      <td>25</td>\n",
       "      <td>2.830910</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wfh time pfh read prachar politics home politi...</td>\n",
       "      <td>['time', 'high', 'time', 'contestant', 'creati...</td>\n",
       "      <td>[0.55672677 0.53856938 0.77486174 0.53856938 0...</td>\n",
       "      <td>2.285503</td>\n",
       "      <td>20</td>\n",
       "      <td>0.589459</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bts system last collection accessory product t...</td>\n",
       "      <td>['product', 'two', 'hat', 'two', 'hat']</td>\n",
       "      <td>[0.53856938 0.88629027 0.95672677 1.96377609 2...</td>\n",
       "      <td>3.107692</td>\n",
       "      <td>14</td>\n",
       "      <td>1.326736</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>manohar parrikar always idol resigning party t...</td>\n",
       "      <td>['parrikar', 'party', 'party', 'parrikar', 'ra...</td>\n",
       "      <td>[1.07713877 0.67713877 1.14629228 2.90056981 0...</td>\n",
       "      <td>3.272661</td>\n",
       "      <td>12</td>\n",
       "      <td>1.267942</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>day 1394 running min 10 km day total 16448 km ...</td>\n",
       "      <td>['km', 'day', '16448', 'km', '03']</td>\n",
       "      <td>[1.07713877 0.26622382 0.53856938 2.90056981 0...</td>\n",
       "      <td>3.049750</td>\n",
       "      <td>13</td>\n",
       "      <td>1.064214</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>win italy 1 66 switzerland 6 0 draw 3 85</td>\n",
       "      <td>['italy', '66', 'switzerland', 'draw', '85']</td>\n",
       "      <td>[0.53856938 0.53856938 0.53856938 0.53856938 0...</td>\n",
       "      <td>2.315468</td>\n",
       "      <td>10</td>\n",
       "      <td>0.538569</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cannot reproduced easily economically able bri...</td>\n",
       "      <td>['easily', 'bring', 'highest', 'shortest', 'po...</td>\n",
       "      <td>[0.53856938 0.53856938 0.53856938 0.53856938 0...</td>\n",
       "      <td>2.374296</td>\n",
       "      <td>11</td>\n",
       "      <td>0.538569</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         CleanedText  \\\n",
       "0  runner around world post photo wearing space r...   \n",
       "1  wfh time pfh read prachar politics home politi...   \n",
       "2  bts system last collection accessory product t...   \n",
       "3  manohar parrikar always idol resigning party t...   \n",
       "4  day 1394 running min 10 km day total 16448 km ...   \n",
       "5           win italy 1 66 switzerland 6 0 draw 3 85   \n",
       "6  cannot reproduced easily economically able bri...   \n",
       "\n",
       "                                       TokenizedText  \\\n",
       "0  ['runner', 'runner', 'explorer', 'runner', 'se...   \n",
       "1  ['time', 'high', 'time', 'contestant', 'creati...   \n",
       "2            ['product', 'two', 'hat', 'two', 'hat']   \n",
       "3  ['parrikar', 'party', 'party', 'parrikar', 'ra...   \n",
       "4                 ['km', 'day', '16448', 'km', '03']   \n",
       "5       ['italy', '66', 'switzerland', 'draw', '85']   \n",
       "6  ['easily', 'bring', 'highest', 'shortest', 'po...   \n",
       "\n",
       "                                              TF-IDF  TF-IDF sum  \\\n",
       "0  [1.43509015 3.43247292 0.53856938 8.20984681 0...    3.446952   \n",
       "1  [0.55672677 0.53856938 0.77486174 0.53856938 0...    2.285503   \n",
       "2  [0.53856938 0.88629027 0.95672677 1.96377609 2...    3.107692   \n",
       "3  [1.07713877 0.67713877 1.14629228 2.90056981 0...    3.272661   \n",
       "4  [1.07713877 0.26622382 0.53856938 2.90056981 0...    3.049750   \n",
       "5  [0.53856938 0.53856938 0.53856938 0.53856938 0...    2.315468   \n",
       "6  [0.53856938 0.53856938 0.53856938 0.53856938 0...    2.374296   \n",
       "\n",
       "   Words quantity  TF-IDF mean  Class  True class  \n",
       "0              25     2.830910      2           2  \n",
       "1              20     0.589459      1           1  \n",
       "2              14     1.326736      2           2  \n",
       "3              12     1.267942      1           1  \n",
       "4              13     1.064214      0           0  \n",
       "5              10     0.538569      0           0  \n",
       "6              11     0.538569      2           2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df = pd.read_csv('../Data/FilteredData.csv', sep= ';', index_col=False)\n",
    "training_data, testing_data = train_test_split(df,random_state = 2000)\n",
    "Y_train=np.array(training_data['Class'].values)\n",
    "Y_test=testing_data['True class'].values\n",
    "X_train = training_data['CleanedText'].values\n",
    "X_test = testing_data['CleanedText'].values\n",
    "Y_train = np.argmax(Y_train, axis=0)\n",
    "print (Y_train)\n",
    "df.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[ 6  0 47 ... 21 21 21]\n"
     ]
    }
   ],
   "source": [
    "documents = reuters.fileids()\n",
    "\n",
    "train_docs_id = list(filter(lambda doc: doc.startswith(\"train\"),\n",
    "                          documents))\n",
    "test_docs_id = list(filter(lambda doc: doc.startswith(\"test\"),\n",
    "                         documents))\n",
    "X_train = [(reuters.raw(doc_id)) for doc_id in train_docs_id]\n",
    "X_test = [(reuters.raw(doc_id)) for doc_id in test_docs_id]\n",
    "mlb = MultiLabelBinarizer()\n",
    "Y_train = mlb.fit_transform([reuters.categories(doc_id)\n",
    "                           for doc_id in train_docs_id])\n",
    "print(Y_train)\n",
    "Y_test = mlb.transform([reuters.categories(doc_id)\n",
    "                      for doc_id in test_docs_id])\n",
    "Y_train = np.argmax(Y_train, axis=1)\n",
    "Y_test = np.argmax(Y_test, axis=1)\n",
    "print (Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done1\n",
      "tf-idf with 26283 features\n",
      "90\n",
      "DNN 0\n",
      "<tensorflow.python.keras.optimizer_v2.adagrad.Adagrad object at 0x150f2e4c0>\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "sparse_categorical = 0\n",
    "n_epochs = [20, 500, 50]  ## DNN--RNN-CNN\n",
    "Random_Deep = [3, 0, 0]  ## DNN--RNN-CNN\n",
    "\n",
    "RMDL.Text_Classification(X_train, Y_train, X_test, Y_test,\n",
    "             batch_size=batch_size,\n",
    "             sparse_categorical=True,\n",
    "             random_deep=Random_Deep,\n",
    "             epochs=n_epochs)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
